{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f4bb50-9c28-4ff9-b980-24b6a43bc91b",
   "metadata": {
    "id": "62f4bb50-9c28-4ff9-b980-24b6a43bc91b"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from abc import abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "360b9f1e-b576-4d64-99be-9124f4ed5056",
   "metadata": {
    "id": "360b9f1e-b576-4d64-99be-9124f4ed5056"
   },
   "outputs": [],
   "source": [
    "def timestep_embedding(timesteps, dim, max_period=10000, repeat_only=False):\n",
    "    \"\"\"\n",
    "    Create sinusoidal timestep embeddings.\n",
    "    :param timesteps: a 1-D Tensor of N indices, one per batch element.\n",
    "                      These may be fractional.\n",
    "    :param dim: the dimension of the output.\n",
    "    :param max_period: controls the minimum frequency of the embeddings.\n",
    "    :return: an [N x dim] Tensor of positional embeddings.\n",
    "    \"\"\"\n",
    "    if not repeat_only:\n",
    "        half = dim // 2\n",
    "        freqs = torch.exp(\n",
    "            -math.log(max_period)\n",
    "            * torch.arange(start=0, end=half, dtype=torch.float32)\n",
    "            / half\n",
    "        ).to(device=timesteps.device)\n",
    "        args = timesteps[:, None].float() * freqs[None]\n",
    "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        if dim % 2:\n",
    "            embedding = torch.cat(\n",
    "                [embedding, torch.zeros_like(embedding[:, :1])], dim=-1\n",
    "            )\n",
    "    else:\n",
    "        embedding = repeat(timesteps, \"b -> b d\", d=dim)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def zero_module(module):\n",
    "    \"\"\"\n",
    "    Zero out the parameters of a module and return it.\n",
    "    \"\"\"\n",
    "    for p in module.parameters():\n",
    "        p.detach().zero_()\n",
    "    return module\n",
    "\n",
    "\n",
    "class TimestepBlock(nn.Module):\n",
    "    @abstractmethod\n",
    "    def forward(self, x, emb):\n",
    "        \"\"\"\n",
    "        Apply the module to `x` given `emb` timestep embeddings.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "class TimestepEmbedSequential(nn.Sequential, TimestepBlock):\n",
    "    \"\"\"\n",
    "    A sequential module that passes timestep embeddings to the children that\n",
    "    support it as an extra input.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x, emb, context=None):\n",
    "        for layer in self:\n",
    "            if isinstance(layer, TimestepBlock):\n",
    "                x = layer(x, emb)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def Normalize(in_channels):\n",
    "    return nn.GroupNorm(\n",
    "        num_groups=32, num_channels=in_channels, eps=1e-6, affine=True\n",
    "    )\n",
    "\n",
    "\n",
    "def count_flops_attn(model, _x, y):\n",
    "    \"\"\"\n",
    "    A counter for the `thop` package to count the operations in an\n",
    "    attention operation.\n",
    "    Meant to be used like:\n",
    "        macs, params = thop.profile(\n",
    "            model,\n",
    "            inputs=(inputs, timestamps),\n",
    "            custom_ops={QKVAttention: QKVAttention.count_flops},\n",
    "        )\n",
    "    \"\"\"\n",
    "    b, c, *spatial = y[0].shape\n",
    "    num_spatial = int(np.prod(spatial))\n",
    "    # We perform two matmuls with the same number of ops.\n",
    "    # The first computes the weight matrix, the second computes\n",
    "    # the combination of the value vectors.\n",
    "    matmul_ops = 2 * b * (num_spatial**2) * c\n",
    "    model.total_ops += th.DoubleTensor([matmul_ops])\n",
    "\n",
    "\n",
    "class QKVAttentionLegacy(nn.Module):\n",
    "    \"\"\"\n",
    "    A module which performs QKV attention.\n",
    "    Matches legacy QKVAttention + input/ouput heads shaping\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_heads):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, qkv):\n",
    "        \"\"\"\n",
    "        Apply QKV attention.\n",
    "        :param qkv: an [N x (H * 3 * C) x T] tensor of Qs, Ks, and Vs.\n",
    "        :return: an [N x (H * C) x T] tensor after attention.\n",
    "        \"\"\"\n",
    "        bs, width, length = qkv.shape\n",
    "        assert width % (3 * self.n_heads) == 0\n",
    "        ch = width // (3 * self.n_heads)\n",
    "        q, k, v = qkv.reshape(bs * self.n_heads, ch * 3, length).split(\n",
    "            ch, dim=1\n",
    "        )\n",
    "        scale = 1 / math.sqrt(math.sqrt(ch))\n",
    "        weight = th.einsum(\n",
    "            \"bct,bcs->bts\", q * scale, k * scale\n",
    "        )  # More stable with f16 than dividing afterwards\n",
    "        weight = th.softmax(weight.float(), dim=-1).type(weight.dtype)\n",
    "        a = th.einsum(\"bts,bcs->bct\", weight, v)\n",
    "        return a.reshape(bs, -1, length)\n",
    "\n",
    "    @staticmethod\n",
    "    def count_flops(model, _x, y):\n",
    "        return count_flops_attn(model, _x, y)\n",
    "\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    An attention block that allows spatial positions to attend to each other.\n",
    "    Originally ported from here, but adapted to the N-d case.\n",
    "    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/models/unet.py#L66.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels,\n",
    "        num_heads=1,\n",
    "        num_head_channels=-1,\n",
    "        use_checkpoint=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        if num_head_channels == -1:\n",
    "            self.num_heads = num_heads\n",
    "        else:\n",
    "            assert channels % num_head_channels == 0, (\n",
    "                f\"q,k,v channels {channels} is \"\n",
    "                f\"not divisible by num_head_channels {num_head_channels}\"\n",
    "            )\n",
    "            self.num_heads = channels // num_head_channels\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.norm = Normalize(channels)\n",
    "        self.qkv = nn.Conv1d(channels, channels * 3, 1)\n",
    "        self.attention = QKVAttentionLegacy(self.num_heads)\n",
    "\n",
    "        self.proj_out = zero_module(nn.Conv1d(channels, channels, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward(\n",
    "            x,\n",
    "        )\n",
    "\n",
    "    def _forward(self, x):\n",
    "        b, c, *spatial = x.shape\n",
    "        x = x.reshape(b, c, -1)\n",
    "        qkv = self.qkv(self.norm(x))\n",
    "        h = self.attention(qkv)\n",
    "        h = self.proj_out(h)\n",
    "        return (x + h).reshape(b, c, *spatial)\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    \"\"\"\n",
    "    A downsampling layer with an optional convolution.\n",
    "    :param channels: channels in the inputs and outputs.\n",
    "    :param use_conv: a bool determining if a convolution is applied.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels, use_conv, out_channels=None, padding=1):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.out_channels = out_channels or channels\n",
    "        self.use_conv = use_conv\n",
    "        if use_conv:\n",
    "            self.op = nn.Conv1d(\n",
    "                self.channels, self.out_channels, 3, stride=2, padding=padding\n",
    "            )#TODO:Mudar\n",
    "        else:\n",
    "            assert self.channels == self.out_channels\n",
    "            self.op = nn.AvgPool1d(kernel_size=2, stride=2)#TODO: Mudar\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.shape[1] == self.channels\n",
    "        return self.op(x)\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    \"\"\"\n",
    "    An upsampling layer with an optional convolution.\n",
    "    :param channels: channels in the inputs and outputs.\n",
    "    :param use_conv: a bool determining if a convolution is applied.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels, use_conv, out_channels=None, padding=1):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.out_channels = out_channels or channels\n",
    "        self.use_conv = use_conv\n",
    "        if use_conv:\n",
    "            self.conv = nn.Conv1d(\n",
    "                self.channels, self.out_channels, 3, padding=padding\n",
    "            )#TODO:Mudar\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.shape[1] == self.channels\n",
    "        x = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n",
    "        if self.use_conv:\n",
    "            x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResBlock(TimestepBlock):\n",
    "    \"\"\"\n",
    "    A residual block that can optionally change the number of channels.\n",
    "    :param channels: the number of input channels.\n",
    "    :param emb_channels: the number of timestep embedding channels.\n",
    "    :param dropout: the rate of dropout.\n",
    "    :param out_channels: if specified, the number of out channels.\n",
    "    :param use_conv: if True and out_channels is specified, use a spatial\n",
    "        convolution instead of a smaller 1x1 convolution to change the\n",
    "        channels in the skip connection.\n",
    "    :param up: if True, use this block for upsampling.\n",
    "    :param down: if True, use this block for downsampling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels,\n",
    "        emb_channels,\n",
    "        dropout,\n",
    "        out_channels=None,\n",
    "        use_conv=False,\n",
    "        use_scale_shift_norm=False,\n",
    "        up=False,\n",
    "        down=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.emb_channels = emb_channels\n",
    "        self.dropout = dropout\n",
    "        self.out_channels = out_channels or channels\n",
    "        self.use_conv = use_conv\n",
    "        self.use_scale_shift_norm = use_scale_shift_norm\n",
    "\n",
    "        self.in_layers = nn.Sequential(\n",
    "            Normalize(channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv1d(channels, self.out_channels, 3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.updown = up or down\n",
    "\n",
    "        if up:\n",
    "            self.h_upd = Upsample(channels, False)\n",
    "            self.x_upd = Upsample(channels, False)\n",
    "        elif down:\n",
    "            self.h_upd = Downsample(channels, False)\n",
    "            self.x_upd = Downsample(channels, False)\n",
    "        else:\n",
    "            self.h_upd = self.x_upd = nn.Identity()\n",
    "\n",
    "        self.emb_layers = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(\n",
    "                emb_channels,\n",
    "                2 * self.out_channels\n",
    "                if use_scale_shift_norm\n",
    "                else self.out_channels,\n",
    "            ),\n",
    "        )\n",
    "        self.out_layers = nn.Sequential(\n",
    "            Normalize(self.out_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            zero_module(\n",
    "                nn.Conv1d(self.out_channels, self.out_channels, 3, padding=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if self.out_channels == channels:\n",
    "            self.skip_connection = nn.Identity()\n",
    "        elif use_conv:\n",
    "            self.skip_connection = nn.Conv1d(\n",
    "                channels, self.out_channels, 3, padding=1\n",
    "            )#TODO:Mudar\n",
    "        else:\n",
    "            self.skip_connection = nn.Conv1d(channels, self.out_channels, 1)#TODO:Mudar\n",
    "\n",
    "    def forward(self, x, emb):\n",
    "        return self._forward(x, emb)\n",
    "\n",
    "    def _forward(self, x, emb):\n",
    "        if self.updown:\n",
    "            in_rest, in_conv = self.in_layers[:-1], self.in_layers[-1]\n",
    "            h = in_rest(x)\n",
    "            h = self.h_upd(h)\n",
    "            x = self.x_upd(x)\n",
    "            h = in_conv(h)\n",
    "        else:\n",
    "            h = self.in_layers(x)\n",
    "        emb_out = self.emb_layers(emb).type(h.dtype)\n",
    "        while len(emb_out.shape) < len(h.shape):\n",
    "            emb_out = emb_out[..., None]\n",
    "        if self.use_scale_shift_norm:\n",
    "            out_norm, out_rest = self.out_layers[0], self.out_layers[1:]\n",
    "            scale, shift = th.chunk(emb_out, 2, dim=1)\n",
    "            h = out_norm(h) * (1 + scale) + shift\n",
    "            h = out_rest(h)\n",
    "        else:\n",
    "            h = h + emb_out\n",
    "            h = self.out_layers(h)\n",
    "        return self.skip_connection(x) + h\n",
    "\n",
    "class UNetModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_size=32,\n",
    "        in_channels=1,\n",
    "        model_channels=32,\n",
    "        out_channels=1,\n",
    "        num_res_blocks=2,\n",
    "        attention_resolutions=[16, 8],\n",
    "        dropout=0.1,\n",
    "        channel_mult=(2, 4, 8),\n",
    "        num_heads=4,\n",
    "        use_scale_shift_norm=False,\n",
    "        resblock_updown=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.in_channels = in_channels\n",
    "        self.model_channels = model_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.attention_resolutions = attention_resolutions\n",
    "        self.dropout = dropout\n",
    "        self.channel_mult = channel_mult\n",
    "        self.num_heads = num_heads\n",
    "        self.use_scale_shift_norm = use_scale_shift_norm\n",
    "        self.resblock_updown = resblock_updown\n",
    "\n",
    "        time_embed_dim = model_channels * 4\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(model_channels, time_embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_embed_dim, time_embed_dim),\n",
    "        )\n",
    "\n",
    "        self.input_blocks = nn.ModuleList([\n",
    "            TimestepEmbedSequential(nn.Conv1d(in_channels, model_channels, 3, padding=1))\n",
    "        ])\n",
    "        input_block_chans = [model_channels]\n",
    "        ch = model_channels\n",
    "        ds = 1\n",
    "\n",
    "        for level, mult in enumerate(channel_mult):\n",
    "            for _ in range(num_res_blocks):\n",
    "                layers = [ResBlock(ch, time_embed_dim, dropout, out_channels=mult * model_channels, use_scale_shift_norm=use_scale_shift_norm)]\n",
    "                ch = mult * model_channels\n",
    "                if ds in attention_resolutions:\n",
    "                    layers.append(AttentionBlock(ch, num_heads=num_heads))\n",
    "                self.input_blocks.append(TimestepEmbedSequential(*layers))\n",
    "                input_block_chans.append(ch)\n",
    "            if level != len(channel_mult) - 1:\n",
    "                out_ch = ch\n",
    "                self.input_blocks.append(TimestepEmbedSequential(Downsample(ch, True, out_channels=out_ch)))\n",
    "                ch = out_ch\n",
    "                input_block_chans.append(ch)\n",
    "                ds *= 2\n",
    "\n",
    "        self.middle_block = TimestepEmbedSequential(\n",
    "            ResBlock(ch, time_embed_dim, dropout, use_scale_shift_norm=use_scale_shift_norm),\n",
    "            AttentionBlock(ch, num_heads=num_heads),\n",
    "            ResBlock(ch, time_embed_dim, dropout, use_scale_shift_norm=use_scale_shift_norm),\n",
    "        )\n",
    "\n",
    "        self.output_blocks = nn.ModuleList([])\n",
    "        for level, mult in list(enumerate(channel_mult))[::-1]:\n",
    "            for i in range(num_res_blocks + 1):\n",
    "                ich = input_block_chans.pop()\n",
    "                layers = [ResBlock(ch + ich, time_embed_dim, dropout, out_channels=model_channels * mult, use_scale_shift_norm=use_scale_shift_norm)]\n",
    "                ch = model_channels * mult\n",
    "                if ds in attention_resolutions:\n",
    "                    layers.append(AttentionBlock(ch, num_heads=num_heads))\n",
    "                if level and i == num_res_blocks:\n",
    "                    out_ch = ch\n",
    "                    layers.append(Upsample(ch, True, out_channels=out_ch))\n",
    "                    ds //= 2\n",
    "                self.output_blocks.append(TimestepEmbedSequential(*layers))\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            Normalize(ch),\n",
    "            nn.SiLU(),\n",
    "            zero_module(nn.Conv1d(ch, out_channels, 3, padding=1)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, timesteps=None, context=None, y=None):\n",
    "        assert timesteps is not None, \"timesteps must be provided\"\n",
    "        hs = []\n",
    "        t_emb = timestep_embedding(timesteps, self.model_channels, repeat_only=False)\n",
    "        emb = self.time_embed(t_emb)\n",
    "\n",
    "        h = x\n",
    "        for module in self.input_blocks:\n",
    "            h = module(h, emb, context)\n",
    "            hs.append(h)\n",
    "        h = self.middle_block(h, emb, context)\n",
    "\n",
    "        for module in self.output_blocks:\n",
    "            h_pop = hs.pop()\n",
    "            if h.shape[2] != h_pop.shape[2]:\n",
    "                h_pop = F.interpolate(h_pop, size=h.shape[2], mode='nearest')\n",
    "            h = torch.cat([h, h_pop], dim=1)\n",
    "            h = module(h, emb, context)\n",
    "\n",
    "        return self.out(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "q6ZXC1uC7Fvf",
   "metadata": {
    "id": "q6ZXC1uC7Fvf"
   },
   "outputs": [],
   "source": [
    "\"\"\" Latent Diffusion V3 from Improved Anomaly Detection\"\"\"\n",
    "from functools import partial\n",
    "from inspect import isfunction\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "\n",
    "def noise_like(shape, device, repeat=False):\n",
    "    repeat_noise = lambda: torch.randn((1, *shape[1:]), device=device).repeat(\n",
    "        shape[0], *((1,) * (len(shape) - 1))\n",
    "    )\n",
    "    noise = lambda: torch.randn(shape, device=device)\n",
    "    return repeat_noise() if repeat else noise()\n",
    "\n",
    "\n",
    "def extract(a, t, x_shape):\n",
    "    b, *_ = t.shape\n",
    "    out = a.gather(-1, t)\n",
    "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "\n",
    "\n",
    "def make_beta_schedule(\n",
    "    schedule, n_timestep, linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3\n",
    "):\n",
    "    if schedule == \"linear\":\n",
    "        betas = (\n",
    "            torch.linspace(\n",
    "                linear_start**0.5,\n",
    "                linear_end**0.5,\n",
    "                n_timestep,\n",
    "                dtype=torch.float64,\n",
    "            )\n",
    "            ** 2\n",
    "        )\n",
    "\n",
    "    elif schedule == \"cosine\":\n",
    "        timesteps = (\n",
    "            torch.arange(n_timestep + 1, dtype=torch.float64) / n_timestep\n",
    "            + cosine_s\n",
    "        )\n",
    "        alphas = timesteps / (1 + cosine_s) * np.pi / 2\n",
    "        alphas = torch.cos(alphas).pow(2)\n",
    "        alphas = alphas / alphas[0]\n",
    "        betas = 1 - alphas[1:] / alphas[:-1]\n",
    "        betas = np.clip(betas, a_min=0, a_max=0.999)\n",
    "\n",
    "    elif schedule == \"sqrt_linear\":\n",
    "        betas = torch.linspace(\n",
    "            linear_start, linear_end, n_timestep, dtype=torch.float64\n",
    "        )\n",
    "    elif schedule == \"sqrt\":\n",
    "        betas = (\n",
    "            torch.linspace(\n",
    "                linear_start, linear_end, n_timestep, dtype=torch.float64\n",
    "            )\n",
    "            ** 0.5\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"schedule '{schedule}' unknown.\")\n",
    "    return betas.numpy()\n",
    "\n",
    "\n",
    "class DDPM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        unet_config,\n",
    "        timesteps: int = 1000,\n",
    "        beta_schedule=\"linear\",\n",
    "        loss_type=\"l2\",\n",
    "        log_every_t=100,\n",
    "        clip_denoised=False,\n",
    "        linear_start=1e-4,\n",
    "        linear_end=2e-2,\n",
    "        cosine_s=8e-3,\n",
    "        original_elbo_weight=0.0,\n",
    "        v_posterior=0.0,\n",
    "        # weight for choosing posterior\n",
    "        # variance as sigma = (1-v) * beta_tilde + v * beta\n",
    "        l_simple_weight=1.0,\n",
    "        parameterization=\"eps\",  # all assuming fixed variance schedules\n",
    "        learn_logvar=False,\n",
    "        logvar_init=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert parameterization in [\n",
    "            \"eps\",\n",
    "            \"x0\",\n",
    "        ], 'currently only supporting \"eps\" and \"x0\"'\n",
    "        self.parameterization = parameterization\n",
    "\n",
    "        self.model = UNetModel(**unet_config.get(\"params\", dict()))\n",
    "\n",
    "        self.clip_denoised = clip_denoised\n",
    "        self.log_every_t = log_every_t\n",
    "\n",
    "        self.v_posterior = v_posterior\n",
    "        self.original_elbo_weight = original_elbo_weight\n",
    "        self.l_simple_weight = l_simple_weight\n",
    "\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "        self.register_schedule(\n",
    "            beta_schedule=beta_schedule,\n",
    "            timesteps=timesteps,\n",
    "            linear_start=linear_start,\n",
    "            linear_end=linear_end,\n",
    "            cosine_s=cosine_s,\n",
    "        )\n",
    "\n",
    "        self.learn_logvar = learn_logvar\n",
    "        self.logvar = torch.full(\n",
    "            fill_value=logvar_init, size=(self.num_timesteps,)\n",
    "        )\n",
    "        if self.learn_logvar:\n",
    "            self.logvar = nn.Parameter(self.logvar, requires_grad=True)\n",
    "\n",
    "    def register_schedule(\n",
    "        self,\n",
    "        beta_schedule=\"linear\",\n",
    "        timesteps=1000,\n",
    "        linear_start=1e-4,\n",
    "        linear_end=2e-2,\n",
    "        cosine_s=8e-3,\n",
    "    ):\n",
    "        betas = make_beta_schedule(\n",
    "            beta_schedule,\n",
    "            timesteps,\n",
    "            linear_start=linear_start,\n",
    "            linear_end=linear_end,\n",
    "            cosine_s=cosine_s,\n",
    "        )\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1.0, alphas_cumprod[:-1])\n",
    "\n",
    "        (timesteps,) = betas.shape\n",
    "        self.num_timesteps = int(timesteps)\n",
    "        self.linear_start = linear_start\n",
    "        self.linear_end = linear_end\n",
    "\n",
    "        to_torch = partial(torch.tensor, dtype=torch.float32)\n",
    "\n",
    "        self.register_buffer(\"betas\", to_torch(betas))\n",
    "        self.register_buffer(\"alphas_cumprod\", to_torch(alphas_cumprod))\n",
    "        self.register_buffer(\n",
    "            \"alphas_cumprod_prev\", to_torch(alphas_cumprod_prev)\n",
    "        )\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.register_buffer(\n",
    "            \"sqrt_alphas_cumprod\", to_torch(np.sqrt(alphas_cumprod))\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"sqrt_one_minus_alphas_cumprod\",\n",
    "            to_torch(np.sqrt(1.0 - alphas_cumprod)),\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"log_one_minus_alphas_cumprod\",\n",
    "            to_torch(np.log(1.0 - alphas_cumprod)),\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"sqrt_recip_alphas_cumprod\",\n",
    "            to_torch(np.sqrt(1.0 / alphas_cumprod)),\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"sqrt_recipm1_alphas_cumprod\",\n",
    "            to_torch(np.sqrt(1.0 / alphas_cumprod - 1)),\n",
    "        )\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = (1 - self.v_posterior) * betas * (\n",
    "            1.0 - alphas_cumprod_prev\n",
    "        ) / (1.0 - alphas_cumprod) + self.v_posterior * betas\n",
    "        # above: equal to 1. / (1. /\n",
    "        # (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n",
    "        self.register_buffer(\n",
    "            \"posterior_variance\", to_torch(posterior_variance)\n",
    "        )\n",
    "        # below: log calculation clipped because the\n",
    "        # posterior variance is 0 at the beginning of the diffusion chain\n",
    "        self.register_buffer(\n",
    "            \"posterior_log_variance_clipped\",\n",
    "            to_torch(np.log(np.maximum(posterior_variance, 1e-20))),\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"posterior_mean_coef1\",\n",
    "            to_torch(\n",
    "                betas * np.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
    "            ),\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"posterior_mean_coef2\",\n",
    "            to_torch(\n",
    "                (1.0 - alphas_cumprod_prev)\n",
    "                * np.sqrt(alphas)\n",
    "                / (1.0 - alphas_cumprod)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if self.parameterization == \"eps\":\n",
    "            lvlb_weights = self.betas**2 / (\n",
    "                2\n",
    "                * self.posterior_variance\n",
    "                * to_torch(alphas)\n",
    "                * (1 - self.alphas_cumprod)\n",
    "            )\n",
    "        elif self.parameterization == \"x0\":\n",
    "            lvlb_weights = (\n",
    "                0.5\n",
    "                * np.sqrt(torch.Tensor(alphas_cumprod))\n",
    "                / (2.0 * 1 - torch.Tensor(alphas_cumprod))\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError(\"mu not supported\")\n",
    "        # TODO how to choose this term\n",
    "        lvlb_weights[0] = lvlb_weights[1]\n",
    "        self.register_buffer(\"lvlb_weights\", lvlb_weights, persistent=False)\n",
    "        assert not torch.isnan(self.lvlb_weights).all()\n",
    "\n",
    "    def q_mean_variance(self, x_start, t):\n",
    "        \"\"\"\n",
    "        Get the distribution q(x_t | x_0).\n",
    "        :param x_start: the [N x C x ...] tensor of\n",
    "        noiseless inputs.\n",
    "        :param t: the number of diffusion steps (minus 1).\n",
    "        Here, 0 means one step.\n",
    "        :return: A tuple (mean, variance, log_variance),\n",
    "        all of x_start's shape.\n",
    "        \"\"\"\n",
    "        mean = extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n",
    "        variance = extract(1.0 - self.alphas_cumprod, t, x_start.shape)\n",
    "        log_variance = extract(\n",
    "            self.log_one_minus_alphas_cumprod, t, x_start.shape\n",
    "        )\n",
    "        return mean, variance, log_variance\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return (\n",
    "            extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t\n",
    "            - extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
    "        )\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        \"\"\"\n",
    "        Compute the mean and variance of the diffusion posterior:\n",
    "            q(x_{t-1} | x_t, x_0)\n",
    "        \"\"\"\n",
    "        posterior_mean = (\n",
    "            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start\n",
    "            + extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        posterior_variance = extract(self.posterior_variance, t, x_t.shape)\n",
    "        posterior_log_variance_clipped = extract(\n",
    "            self.posterior_log_variance_clipped, t, x_t.shape\n",
    "        )\n",
    "        return (\n",
    "            posterior_mean,\n",
    "            posterior_variance,\n",
    "            posterior_log_variance_clipped,\n",
    "        )\n",
    "\n",
    "    def p_mean_variance(self, x, t, clip_denoised: bool, return_x0=False):\n",
    "        \"\"\"\n",
    "        Apply the model to get p(x_{t-1} | x_t)\n",
    "        :param model: the model, which takes a signal and a batch of timesteps\n",
    "                      as input.\n",
    "        :param x: the [N x C x ...] tensor at time t.\n",
    "        :param t: a 1-D Tensor of timesteps.\n",
    "        :param clip_denoised: if True, clip the denoised signal into [-1, 1].\n",
    "        \"\"\"\n",
    "        model_out = self.model(x, t)\n",
    "        if self.parameterization == \"eps\":\n",
    "            x_recon = self.predict_start_from_noise(x, t=t, noise=model_out)\n",
    "        elif self.parameterization == \"x0\":\n",
    "            x_recon = model_out\n",
    "\n",
    "        if clip_denoised:\n",
    "            x_recon.clamp_(-1.0, 1.0)\n",
    "\n",
    "        (\n",
    "            model_mean,\n",
    "            posterior_variance,\n",
    "            posterior_log_variance,\n",
    "        ) = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n",
    "        if return_x0:\n",
    "            return (\n",
    "                model_mean,\n",
    "                posterior_variance,\n",
    "                posterior_log_variance,\n",
    "                x_recon,\n",
    "            )\n",
    "        else:\n",
    "            return model_mean, posterior_variance, posterior_log_variance\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(\n",
    "        self,\n",
    "        x,\n",
    "        t,\n",
    "        clip_denoised=True,\n",
    "        repeat_noise=False,\n",
    "        return_x0=False,\n",
    "        temperature=1.0,\n",
    "        noise_dropout=0.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Sample x_{t-1} from the model at the given timestep.\n",
    "        :param x: the current tensor at x_{t-1}.\n",
    "        :param t: the value of t, starting at 0 for the first diffusion step.\n",
    "        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].\n",
    "        \"\"\"\n",
    "\n",
    "        b, *_, device = *x.shape, x.device\n",
    "        outputs = self.p_mean_variance(\n",
    "            x=x,\n",
    "            t=t,\n",
    "            clip_denoised=clip_denoised,\n",
    "            return_x0=return_x0,\n",
    "        )\n",
    "        if return_x0:\n",
    "            model_mean, _, model_log_variance, x0 = outputs\n",
    "        else:\n",
    "            model_mean, _, model_log_variance = outputs\n",
    "\n",
    "        noise = noise_like(x.shape, device, repeat_noise) * temperature\n",
    "        if noise_dropout > 0.0:\n",
    "            noise = torch.nn.functional.dropout(noise, p=noise_dropout)\n",
    "        # no noise when t == 0\n",
    "        nonzero_mask = (1 - (t == 0).float()).reshape(\n",
    "            b, *((1,) * (len(x.shape) - 1))\n",
    "        )\n",
    "        if return_x0:\n",
    "            return (\n",
    "                model_mean\n",
    "                + nonzero_mask * (0.5 * model_log_variance).exp() * noise,\n",
    "                x0,\n",
    "            )\n",
    "        else:\n",
    "            return (\n",
    "                model_mean\n",
    "                + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n",
    "            )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, shape, return_intermediates=False):\n",
    "        device = self.betas.device\n",
    "\n",
    "        b = shape[0]\n",
    "        img = torch.randn(shape, device=device)\n",
    "        intermediates = [img]\n",
    "\n",
    "        for i in tqdm(\n",
    "            reversed(range(0, self.num_timesteps)),\n",
    "            desc=\"sampling loop time step\",\n",
    "            total=self.num_timesteps,\n",
    "        ):\n",
    "            img = self.p_sample(\n",
    "                img,\n",
    "                torch.full((b,), i, device=device, dtype=torch.long),\n",
    "                clip_denoised=self.clip_denoised,\n",
    "            )\n",
    "            if i % self.log_every_t == 0 or i == self.num_timesteps - 1:\n",
    "                intermediates.append(img)\n",
    "        if return_intermediates:\n",
    "            return img, intermediates\n",
    "        return img\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size=16, return_intermediates=False):\n",
    "        image_size = self.image_size\n",
    "        channels = self.channels\n",
    "        return self.p_sample_loop(\n",
    "            (batch_size, channels, image_size, image_size),\n",
    "            return_intermediates=return_intermediates,\n",
    "        )\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        \"\"\"\n",
    "        Diffuse the data for a given number of diffusion steps.\n",
    "        In other words, sample from q(x_t | x_0).\n",
    "        :param x_start: the initial data batch.\n",
    "        :param t: the number of diffusion steps (minus 1). Here,\n",
    "        0 means one step.\n",
    "        :param noise: if specified, the split-out normal noise.\n",
    "        :return: A noisy version of x_start.\n",
    "        \"\"\"\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        return (\n",
    "            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n",
    "            + extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape)\n",
    "            * noise\n",
    "        )\n",
    "\n",
    "    def get_loss(self, pred, target, mean=True):\n",
    "        if self.loss_type == \"l1\":\n",
    "            loss = (target - pred).abs()\n",
    "            if mean:\n",
    "                loss = loss.mean()\n",
    "        elif self.loss_type == \"l2\":\n",
    "            if mean:\n",
    "                loss = torch.nn.functional.mse_loss(target, pred)\n",
    "            else:\n",
    "                loss = torch.nn.functional.mse_loss(\n",
    "                    target, pred, reduction=\"none\"\n",
    "                )\n",
    "        else:\n",
    "            raise NotImplementedError(\"unknown loss type '{loss_type}'\")\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def p_losses(self, x_start, t, noise=None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n",
    "        model_output = self.model(x_noisy, t)\n",
    "\n",
    "        loss_dict = {}\n",
    "        if self.parameterization == \"eps\":\n",
    "            target = noise\n",
    "        elif self.parameterization == \"x0\":\n",
    "            target = x_start\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                f\"Paramterization {self.parameterization} not yet supported\"\n",
    "            )\n",
    "\n",
    "        loss_simple = self.get_loss(model_output, target, mean=False).mean(\n",
    "            dim=[1, 2]\n",
    "        )\n",
    "        loss_dict.update({f\"loss_simple\": loss_simple.mean()})\n",
    "\n",
    "        logvar_t = self.logvar[t].to(x_start.device)\n",
    "        loss = loss_simple / torch.exp(logvar_t) + logvar_t\n",
    "        if self.learn_logvar:\n",
    "            loss_dict.update({f\"loss_gamma\": loss.mean()})\n",
    "            loss_dict.update({\"logvar\": self.logvar.data.mean()})\n",
    "\n",
    "        loss = self.l_simple_weight * loss.mean()\n",
    "\n",
    "        loss_vlb = self.get_loss(model_output, target, mean=False).mean(\n",
    "            dim=(1, 2)\n",
    "        )\n",
    "        loss_vlb = (self.lvlb_weights[t] * loss_vlb).mean()\n",
    "        loss_dict.update({f\"loss_vlb\": loss_vlb})\n",
    "        loss += self.original_elbo_weight * loss_vlb\n",
    "        loss_dict.update({f\"loss\": loss})\n",
    "\n",
    "        return loss, loss_dict\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        t = torch.randint(\n",
    "            0, self.num_timesteps, (x.shape[0],), device=x.device\n",
    "        ).long()\n",
    "        return self.p_losses(x, t, *args, **kwargs)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.learning_rate = 1e-4\n",
    "        lr = self.learning_rate\n",
    "        params = list(self.model.parameters())\n",
    "        if self.learn_logvar:\n",
    "            print(\"Diffusion model optimizing logvar\")\n",
    "            params.append(self.logvar)\n",
    "        opt = torch.optim.AdamW(params, lr=lr)\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6G49dNg5_uKd",
   "metadata": {
    "id": "6G49dNg5_uKd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# 데이터 생성 함수\n",
    "def generate_data(num_normal=1000, num_anomalous=200):\n",
    "    normal_data = np.random.normal(loc=0, scale=1, size=(num_normal, 1, 32))\n",
    "    anomalous_data = np.random.uniform(low=-3, high=3, size=(num_anomalous, 1, 32))\n",
    "    normal_labels = np.zeros((num_normal,))\n",
    "    anomalous_labels = np.ones((num_anomalous,))\n",
    "\n",
    "    data = np.concatenate([normal_data, anomalous_data], axis=0)\n",
    "    labels = np.concatenate([normal_labels, anomalous_labels], axis=0)\n",
    "\n",
    "    return torch.tensor(data, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# 데이터 준비 (훈련 시 정상 데이터의 레이블 제거)\n",
    "train_data, _ = generate_data(num_normal=1000)\n",
    "test_data, test_labels = generate_data(num_normal=500, num_anomalous=100)\n",
    "\n",
    "# 데이터로더 생성\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(TensorDataset(train_data), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(test_data, test_labels), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "HVtw0yC2DjCU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVtw0yC2DjCU",
    "outputId": "5972dd48-ecfb-43b5-fb1c-13d7c1558532"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1200, 1, 32]), torch.Size([600, 1, 32]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "HvOmN170AUyk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "HvOmN170AUyk",
    "outputId": "834853b5-0a40-49fe-b329-7896a0b619d1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정상 데이터와 이상 데이터에서 일부 샘플만 선택하여 히스토그램 작성\n",
    "normal_values = train_data.numpy().flatten()\n",
    "anomalous_values = test_data[test_labels == 1].numpy().flatten()\n",
    "\n",
    "# 히스토그램 그리기\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(normal_values, bins=50, alpha=0.6, color='blue', label='Normal')\n",
    "plt.hist(anomalous_values, bins=50, alpha=0.6, color='red', label='Anomalous')\n",
    "\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Normal and Anomalous Data')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dDr09hdY_uO1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDr09hdY_uO1",
    "outputId": "2a0de52d-c3fd-4c72-e66f-4ff337abe171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.9831\n",
      "Epoch 2/10, Loss: 0.8904\n",
      "Epoch 3/10, Loss: 0.8334\n",
      "Epoch 4/10, Loss: 0.7647\n",
      "Epoch 5/10, Loss: 0.7008\n",
      "Epoch 6/10, Loss: 0.6601\n",
      "Epoch 7/10, Loss: 0.6253\n",
      "Epoch 8/10, Loss: 0.6186\n",
      "Epoch 9/10, Loss: 0.6029\n",
      "Epoch 10/10, Loss: 0.5771\n"
     ]
    }
   ],
   "source": [
    "# DDPM 모델 초기화\n",
    "unet_config = {\n",
    "    \"params\": {\n",
    "        \"image_size\": 32,\n",
    "        \"in_channels\": 1,\n",
    "        \"model_channels\": 32,\n",
    "        \"out_channels\": 1,\n",
    "        \"num_res_blocks\": 2,\n",
    "        \"attention_resolutions\": [16, 8],\n",
    "        \"dropout\": 0.1,\n",
    "        \"channel_mult\": (2, 4, 8),\n",
    "        \"num_heads\": 4,\n",
    "    }\n",
    "}\n",
    "\n",
    "ddpm = DDPM(unet_config=unet_config)\n",
    "optimizer = ddpm.configure_optimizers()\n",
    "\n",
    "# DDPM 학습\n",
    "num_epochs = 10\n",
    "ddpm.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        x = batch[0].to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "        optimizer.zero_grad()\n",
    "        loss, _ = ddpm(x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "UZfAmhriAggl",
   "metadata": {
    "id": "UZfAmhriAggl"
   },
   "outputs": [],
   "source": [
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "BRN3f9Go_uRl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "BRN3f9Go_uRl",
    "outputId": "9a75157c-c058-4429-d493-dadade10e41a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-ec5b5792ebab>:27: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot([\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.1636, Recall: 0.6300, F1 Score: 0.2598\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# DDPM 평가 모드\n",
    "ddpm.eval()\n",
    "anomaly_scores = []\n",
    "y_true = []\n",
    "\n",
    "# 데이터셋에서 이상 탐지 수행\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x, labels = batch\n",
    "        x = x.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "        labels = labels.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "        t = torch.randint(0, ddpm.num_timesteps, (x.shape[0],), device=x.device).long()\n",
    "        x_noisy = ddpm.q_sample(x, t)\n",
    "        x_reconstructed = ddpm.p_sample(x_noisy, t)\n",
    "\n",
    "        loss = torch.nn.functional.mse_loss(x, x_reconstructed, reduction='none').mean(dim=[1, 2])\n",
    "        anomaly_scores.extend(loss.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# 박스플롯을 이용한 시각화\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.boxplot([\n",
    "    [anomaly_scores[i] for i in range(len(y_true)) if y_true[i] == 0],  # 정상 데이터\n",
    "    [anomaly_scores[i] for i in range(len(y_true)) if y_true[i] == 1]   # 이상 데이터\n",
    "], labels=['Normal', 'Anomalous'])\n",
    "\n",
    "# 임계값 표시 (빨간색 수평선)\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label=f'Threshold ({threshold:.4f})')\n",
    "\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.title('Anomaly Detection using DDPM')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 정밀도, 재현율, F1 점수 계산\n",
    "predictions = [1 if score > threshold else 0 for score in anomaly_scores]\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, predictions, average='binary')\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aKBXWH8t_uXO",
   "metadata": {
    "id": "aKBXWH8t_uXO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W_7C2PpnC1k9",
   "metadata": {
    "id": "W_7C2PpnC1k9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5zFBse2S_uaF",
   "metadata": {
    "id": "5zFBse2S_uaF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zFnxtzh9_udY",
   "metadata": {
    "id": "zFnxtzh9_udY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dc38fe-4290-49b8-b0b2-443f8f5a23ad",
   "metadata": {
    "id": "a5dc38fe-4290-49b8-b0b2-443f8f5a23ad"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
